{
  "path": "process/init/app/run.sh",
  "mode": "+x",
  "content": "#!/usr/bin/env bash\n# cmd_extractor  process/init/app\n# {\"style\":\"cmd_extractor\",\"cmd\":\"\\n        deepdive db init\\n\\n        cd \\\"$DEEPDIVE_APP\\\"\\n        # run legacy schema.sql\\n        if [[ -r schema.sql ]]; then\\n            deepdive db prompt <schema.sql\\n        fi\\n        # run legacy init script\\n        if [[ -x input/init.sh ]]; then\\n            input/init.sh\\n        fi\\n        \",\"name\":\"process/init/app\"}\nset -xeuo pipefail\ncd \"$(dirname \"$0\")\"\n\n\n\nexport DEEPDIVE_CURRENT_PROCESS_NAME='process/init/app'\n\n        deepdive db init\n\n        cd \"$DEEPDIVE_APP\"\n        # run legacy schema.sql\n        if [[ -r schema.sql ]]; then\n            deepdive db prompt <schema.sql\n        fi\n        # run legacy init script\n        if [[ -x input/init.sh ]]; then\n            input/init.sh\n        fi\n        \n\n\n"
}
{
  "path": "process/init/relation/reviews/run.sh",
  "mode": "+x",
  "content": "#!/usr/bin/env bash\n# cmd_extractor  process/init/relation/reviews\n# {\"style\":\"cmd_extractor\",\"cmd\":\"deepdive create table 'reviews' && deepdive load 'reviews'\",\"dependencies_\":[\"process/init/app\"],\"output_relation\":\"reviews\",\"output_\":\"data/reviews\",\"name\":\"process/init/relation/reviews\"}\nset -xeuo pipefail\ncd \"$(dirname \"$0\")\"\n\n\n\nexport DEEPDIVE_CURRENT_PROCESS_NAME='process/init/relation/reviews'\ndeepdive create table 'reviews' && deepdive load 'reviews'\n\n\n"
}
{
  "path": "process/init/relation/sentiments/run.sh",
  "mode": "+x",
  "content": "#!/usr/bin/env bash\n# cmd_extractor  process/init/relation/sentiments\n# {\"style\":\"cmd_extractor\",\"cmd\":\"deepdive create table 'sentiments' && deepdive load 'sentiments'\",\"dependencies_\":[\"process/init/app\"],\"output_relation\":\"sentiments\",\"output_\":\"data/sentiments\",\"name\":\"process/init/relation/sentiments\"}\nset -xeuo pipefail\ncd \"$(dirname \"$0\")\"\n\n\n\nexport DEEPDIVE_CURRENT_PROCESS_NAME='process/init/relation/sentiments'\ndeepdive create table 'sentiments' && deepdive load 'sentiments'\n\n\n"
}
{
  "path": "process/ext_review_sentiment/run.sh",
  "mode": "+x",
  "content": "#!/usr/bin/env bash\n# cmd_extractor  process/ext_review_sentiment\n# {\"cmd\":\"\\n\\n\\t# TODO use temporary table\\n\\tdeepdive create table \\\"review_sentiment\\\"\\n\\tdeepdive sql 'INSERT INTO review_sentiment SELECT DISTINCT R0.review_id, R1.index, 0 AS id, \\nCASE WHEN R1.index = R0.sentiment THEN true\\n     ELSE false\\nEND AS label\\n          FROM reviews R0, sentiments R1\\n        \\n          '\\n\\t# TODO rename temporary table to replace output_relation\\n\\t\\n        \",\"input_relations\":[\"reviews\",\"sentiments\"],\"output_relation\":\"review_sentiment\",\"style\":\"cmd_extractor\",\"dependencies_\":[],\"input_\":[\"data/reviews\",\"data/sentiments\"],\"output_\":\"data/review_sentiment\",\"name\":\"process/ext_review_sentiment\"}\nset -xeuo pipefail\ncd \"$(dirname \"$0\")\"\n\n\n\nexport DEEPDIVE_CURRENT_PROCESS_NAME='process/ext_review_sentiment'\n\n\n\t# TODO use temporary table\n\tdeepdive create table \"review_sentiment\"\n\tdeepdive sql 'INSERT INTO review_sentiment SELECT DISTINCT R0.review_id, R1.index, 0 AS id, \nCASE WHEN R1.index = R0.sentiment THEN true\n     ELSE false\nEND AS label\n          FROM reviews R0, sentiments R1\n        \n          '\n\t# TODO rename temporary table to replace output_relation\n\t\n        \n\n\n"
}
{
  "path": "process/grounding/variable_id_partition/run.sh",
  "mode": "+x",
  "content": "#!/usr/bin/env bash\n# cmd_extractor  process/grounding/variable_id_partition\n# {\"dependencies_\":[\"data/review_sentiment\"],\"style\":\"cmd_extractor\",\"cmd\":\"\\n        : ${DEEPDIVE_GROUNDING_DIR:=\\\"$DEEPDIVE_APP\\\"/run/model/grounding}\\n\\n        RANGE_BEGIN=0 \\\\\\n        partition_id_range 'review_sentiment' | {\\n            # record the base\\n            variableCountTotal=0\\n            while read table begin excludeEnd; do\\n                varPath=\\\"$DEEPDIVE_GROUNDING_DIR\\\"/variable/${table}\\n                mkdir -p \\\"$varPath\\\"\\n                cd \\\"$varPath\\\"\\n                echo $begin                      >id_begin\\n                echo $excludeEnd                 >id_exclude_end\\n                echo $(( $excludeEnd - $begin )) >count\\n                variableCountTotal=$excludeEnd\\n            done\\n            # record the final count\\n            echo $variableCountTotal >\\\"$DEEPDIVE_GROUNDING_DIR\\\"/variable_count\\n        }\\n        \",\"name\":\"process/grounding/variable_id_partition\"}\nset -xeuo pipefail\ncd \"$(dirname \"$0\")\"\n\n\n\nexport DEEPDIVE_CURRENT_PROCESS_NAME='process/grounding/variable_id_partition'\n\n        : ${DEEPDIVE_GROUNDING_DIR:=\"$DEEPDIVE_APP\"/run/model/grounding}\n\n        RANGE_BEGIN=0 \\\n        partition_id_range 'review_sentiment' | {\n            # record the base\n            variableCountTotal=0\n            while read table begin excludeEnd; do\n                varPath=\"$DEEPDIVE_GROUNDING_DIR\"/variable/${table}\n                mkdir -p \"$varPath\"\n                cd \"$varPath\"\n                echo $begin                      >id_begin\n                echo $excludeEnd                 >id_exclude_end\n                echo $(( $excludeEnd - $begin )) >count\n                variableCountTotal=$excludeEnd\n            done\n            # record the final count\n            echo $variableCountTotal >\"$DEEPDIVE_GROUNDING_DIR\"/variable_count\n        }\n        \n\n\n"
}
{
  "path": "process/grounding/variable/review_sentiment/assign_id/run.sh",
  "mode": "+x",
  "content": "#!/usr/bin/env bash\n# cmd_extractor  process/grounding/variable/review_sentiment/assign_id\n# {\"dependencies_\":[\"process/grounding/variable_id_partition\"],\"style\":\"cmd_extractor\",\"cmd\":\"\\n        : ${DEEPDIVE_GROUNDING_DIR:=\\\"$DEEPDIVE_APP\\\"/run/model/grounding}\\n        table='review_sentiment'\\n\\n        cd \\\"$DEEPDIVE_GROUNDING_DIR\\\"/variable/${table}\\n        baseId=$(cat id_begin)\\n\\n        # assign id to all rows according to the paritition\\n        deepdive db assign_sequential_id $table 'id' $baseId\\n\\n        \\n        \",\"name\":\"process/grounding/variable/review_sentiment/assign_id\"}\nset -xeuo pipefail\ncd \"$(dirname \"$0\")\"\n\n\n\nexport DEEPDIVE_CURRENT_PROCESS_NAME='process/grounding/variable/review_sentiment/assign_id'\n\n        : ${DEEPDIVE_GROUNDING_DIR:=\"$DEEPDIVE_APP\"/run/model/grounding}\n        table='review_sentiment'\n\n        cd \"$DEEPDIVE_GROUNDING_DIR\"/variable/${table}\n        baseId=$(cat id_begin)\n\n        # assign id to all rows according to the paritition\n        deepdive db assign_sequential_id $table 'id' $baseId\n\n        \n        \n\n\n"
}
{
  "path": "process/grounding/variable_holdout/run.sh",
  "mode": "+x",
  "content": "#!/usr/bin/env bash\n# cmd_extractor  process/grounding/variable_holdout\n# {\"dependencies_\":[\"process/grounding/variable/review_sentiment/assign_id\"],\"style\":\"cmd_extractor\",\"cmd\":\"\\n        : ${DEEPDIVE_GROUNDING_DIR:=\\\"$DEEPDIVE_APP\\\"/run/model/grounding}\\n\\n        deepdive create table 'dd_graph_variables_holdout' \\\\\\n            variable_id:BIGINT:'PRIMARY KEY' \\\\\\n            #\\n        deepdive create table 'dd_graph_variables_observation' \\\\\\n            variable_id:BIGINT:'PRIMARY KEY' \\\\\\n            #\\n        deepdive sql '\\n                INSERT INTO \\\"dd_graph_variables_holdout\\\" SELECT \\\"id\\\"\\nFROM \\\"review_sentiment\\\"\\n\\nWHERE \\\"label\\\" IS NOT NULL AND RANDOM() < 0.25;\\n            '\\n        \",\"name\":\"process/grounding/variable_holdout\"}\nset -xeuo pipefail\ncd \"$(dirname \"$0\")\"\n\n\n\nexport DEEPDIVE_CURRENT_PROCESS_NAME='process/grounding/variable_holdout'\n\n        : ${DEEPDIVE_GROUNDING_DIR:=\"$DEEPDIVE_APP\"/run/model/grounding}\n\n        deepdive create table 'dd_graph_variables_holdout' \\\n            variable_id:BIGINT:'PRIMARY KEY' \\\n            #\n        deepdive create table 'dd_graph_variables_observation' \\\n            variable_id:BIGINT:'PRIMARY KEY' \\\n            #\n        deepdive sql '\n                INSERT INTO \"dd_graph_variables_holdout\" SELECT \"id\"\nFROM \"review_sentiment\"\n\nWHERE \"label\" IS NOT NULL AND RANDOM() < 0.25;\n            '\n        \n\n\n"
}
{
  "path": "process/grounding/variable/review_sentiment/dump/run.sh",
  "mode": "+x",
  "content": "#!/usr/bin/env bash\n# cmd_extractor  process/grounding/variable/review_sentiment/dump\n# {\"dependencies_\":[\"process/grounding/variable_holdout\"],\"style\":\"cmd_extractor\",\"cmd\":\"\\n        : ${DEEPDIVE_GROUNDING_DIR:=\\\"$DEEPDIVE_APP\\\"/run/model/grounding}\\n        table='review_sentiment'\\n\\n        varPath=\\\"$DEEPDIVE_GROUNDING_DIR\\\"/variable/'review_sentiment'\\n        mkdir -p \\\"$varPath\\\"\\n        cd \\\"$varPath\\\"\\n        find . -name 'variables.part-*.bin.bz2' -exec rm -rf {} +\\n        export DEEPDIVE_LOAD_FORMAT=tsv\\n        export DEEPDIVE_UNLOAD_MATERIALIZED=false\\n\\n        # dump the variables, joining the holdout query to determine the type of each variable\\n        deepdive compute execute \\\\\\n            input_sql='SELECT \\\"id\\\"\\n     , \\\"variable_role\\\"\\n     , CASE WHEN variable_role = 0 THEN 0\\n                          ELSE (CASE WHEN label THEN 1 ELSE 0 END) + 0.0\\n                      END AS \\\"init_value\\\"\\n     , \\\"variable_type\\\"\\n     , \\\"cardinality\\\"\\nFROM (SELECT \\\"id\\\" AS \\\"id\\\"\\n     , CASE WHEN               observation.variable_id IS NOT NULL\\n                                     AND variables.\\\"label\\\" IS NOT NULL THEN 2\\n                                    WHEN               holdout.variable_id IS NOT NULL THEN 0\\n                                    WHEN variables.\\\"label\\\" IS NOT NULL THEN 1\\n                                                                                       ELSE 0\\n                                END AS \\\"variable_role\\\"\\n     , \\\"variables\\\".\\\"label\\\" AS \\\"label\\\"\\n     , 0 AS \\\"variable_type\\\"\\n     , 2 AS \\\"cardinality\\\"\\nFROM \\\"review_sentiment\\\" \\\"variables\\\"\\nLEFT OUTER JOIN \\\"dd_graph_variables_holdout\\\" \\\"holdout\\\" ON \\\"variables\\\".\\\"id\\\" = \\\"holdout\\\".\\\"variable_id\\\" LEFT OUTER JOIN \\\"dd_graph_variables_observation\\\" \\\"observation\\\" ON \\\"variables\\\".\\\"id\\\" = \\\"observation\\\".\\\"variable_id\\\") \\\"variables\\\"' \\\\\\n            command='\\n                format_converter variable /dev/stdin >(pbzip2 >variables.part-${DEEPDIVE_CURRENT_PROCESS_INDEX}.bin.bz2)\\n            ' \\\\\\n            output_relation=\\n        \",\"name\":\"process/grounding/variable/review_sentiment/dump\"}\nset -xeuo pipefail\ncd \"$(dirname \"$0\")\"\n\n\n\nexport DEEPDIVE_CURRENT_PROCESS_NAME='process/grounding/variable/review_sentiment/dump'\n\n        : ${DEEPDIVE_GROUNDING_DIR:=\"$DEEPDIVE_APP\"/run/model/grounding}\n        table='review_sentiment'\n\n        varPath=\"$DEEPDIVE_GROUNDING_DIR\"/variable/'review_sentiment'\n        mkdir -p \"$varPath\"\n        cd \"$varPath\"\n        find . -name 'variables.part-*.bin.bz2' -exec rm -rf {} +\n        export DEEPDIVE_LOAD_FORMAT=tsv\n        export DEEPDIVE_UNLOAD_MATERIALIZED=false\n\n        # dump the variables, joining the holdout query to determine the type of each variable\n        deepdive compute execute \\\n            input_sql='SELECT \"id\"\n     , \"variable_role\"\n     , CASE WHEN variable_role = 0 THEN 0\n                          ELSE (CASE WHEN label THEN 1 ELSE 0 END) + 0.0\n                      END AS \"init_value\"\n     , \"variable_type\"\n     , \"cardinality\"\nFROM (SELECT \"id\" AS \"id\"\n     , CASE WHEN               observation.variable_id IS NOT NULL\n                                     AND variables.\"label\" IS NOT NULL THEN 2\n                                    WHEN               holdout.variable_id IS NOT NULL THEN 0\n                                    WHEN variables.\"label\" IS NOT NULL THEN 1\n                                                                                       ELSE 0\n                                END AS \"variable_role\"\n     , \"variables\".\"label\" AS \"label\"\n     , 0 AS \"variable_type\"\n     , 2 AS \"cardinality\"\nFROM \"review_sentiment\" \"variables\"\nLEFT OUTER JOIN \"dd_graph_variables_holdout\" \"holdout\" ON \"variables\".\"id\" = \"holdout\".\"variable_id\" LEFT OUTER JOIN \"dd_graph_variables_observation\" \"observation\" ON \"variables\".\"id\" = \"observation\".\"variable_id\") \"variables\"' \\\n            command='\n                format_converter variable /dev/stdin >(pbzip2 >variables.part-${DEEPDIVE_CURRENT_PROCESS_INDEX}.bin.bz2)\n            ' \\\n            output_relation=\n        \n\n\n"
}
{
  "path": "process/grounding/factor/inf_istrue_review_sentiment/materialize/run.sh",
  "mode": "+x",
  "content": "#!/usr/bin/env bash\n# cmd_extractor  process/grounding/factor/inf_istrue_review_sentiment/materialize\n# {\"dependencies_\":[\"process/grounding/variable/review_sentiment/assign_id\"],\"input_\":[\"data/reviews\",\"data/review_feature\"],\"style\":\"cmd_extractor\",\"cmd\":\"\\n            : ${DEEPDIVE_GROUNDING_DIR:=\\\"$DEEPDIVE_APP\\\"/run/model/grounding}\\n\\n            # materialize factors using user input_query that pulls in assigned ids to involved variables\\n            deepdive create table 'dd_factors_inf_istrue_review_sentiment' as '\\n          SELECT R0.id AS \\\"review_sentiment.R0.id\\\" , R2.feature AS \\\"dd_weight_column_0\\\" \\n          FROM review_sentiment R0, reviews R1, review_feature R2\\n        WHERE R1.review_id = R0.index  AND R2.id = R0.index '\\n\\n            # find distinct weights for the factors into a separate table\\n            deepdive create table 'dd_weights_inf_istrue_review_sentiment' as 'SELECT \\\"dd_weight_column_0\\\"\\n     , false AS \\\"isfixed\\\"\\n     , 0 AS \\\"initvalue\\\"\\n     , -1 AS \\\"id\\\"\\nFROM \\\"dd_factors_inf_istrue_review_sentiment\\\"\\n\\n\\nGROUP BY \\\"dd_weight_column_0\\\"'\\n        \",\"name\":\"process/grounding/factor/inf_istrue_review_sentiment/materialize\"}\nset -xeuo pipefail\ncd \"$(dirname \"$0\")\"\n\n\n\nexport DEEPDIVE_CURRENT_PROCESS_NAME='process/grounding/factor/inf_istrue_review_sentiment/materialize'\n\n            : ${DEEPDIVE_GROUNDING_DIR:=\"$DEEPDIVE_APP\"/run/model/grounding}\n\n            # materialize factors using user input_query that pulls in assigned ids to involved variables\n            deepdive create table 'dd_factors_inf_istrue_review_sentiment' as '\n          SELECT R0.id AS \"review_sentiment.R0.id\" , R2.feature AS \"dd_weight_column_0\" \n          FROM review_sentiment R0, reviews R1, review_feature R2\n        WHERE R1.review_id = R0.index  AND R2.id = R0.index '\n\n            # find distinct weights for the factors into a separate table\n            deepdive create table 'dd_weights_inf_istrue_review_sentiment' as 'SELECT \"dd_weight_column_0\"\n     , false AS \"isfixed\"\n     , 0 AS \"initvalue\"\n     , -1 AS \"id\"\nFROM \"dd_factors_inf_istrue_review_sentiment\"\n\n\nGROUP BY \"dd_weight_column_0\"'\n        \n\n\n"
}
{
  "path": "process/grounding/weight_id_partition/run.sh",
  "mode": "+x",
  "content": "#!/usr/bin/env bash\n# cmd_extractor  process/grounding/weight_id_partition\n# {\"dependencies_\":[\"process/grounding/factor/inf_istrue_review_sentiment/materialize\"],\"style\":\"cmd_extractor\",\"cmd\":\"\\n        : ${DEEPDIVE_GROUNDING_DIR:=\\\"$DEEPDIVE_APP\\\"/run/model/grounding}\\n\\n        # partition the id range for weights\\n        RANGE_BEGIN=0 RANGE_STEP=1 \\\\\\n        partition_id_range 'dd_weights_inf_istrue_review_sentiment' | {\\n            weightsCountTotal=0\\n            while read table begin excludeEnd; do\\n                factor=${table#'dd_weights_'}\\n                facPath=\\\"$DEEPDIVE_GROUNDING_DIR\\\"/factor/${factor}\\n                mkdir -p \\\"$facPath\\\"\\n                cd \\\"$facPath\\\"\\n                echo $begin                      >weights_id_begin\\n                echo $excludeEnd                 >weights_id_exclude_end\\n                echo $(( $excludeEnd - $begin )) >weights_count\\n                weightsCountTotal=$excludeEnd\\n            done\\n            echo $weightsCountTotal >\\\"$DEEPDIVE_GROUNDING_DIR\\\"/factor/weights_count\\n        }\\n        \",\"name\":\"process/grounding/weight_id_partition\"}\nset -xeuo pipefail\ncd \"$(dirname \"$0\")\"\n\n\n\nexport DEEPDIVE_CURRENT_PROCESS_NAME='process/grounding/weight_id_partition'\n\n        : ${DEEPDIVE_GROUNDING_DIR:=\"$DEEPDIVE_APP\"/run/model/grounding}\n\n        # partition the id range for weights\n        RANGE_BEGIN=0 RANGE_STEP=1 \\\n        partition_id_range 'dd_weights_inf_istrue_review_sentiment' | {\n            weightsCountTotal=0\n            while read table begin excludeEnd; do\n                factor=${table#'dd_weights_'}\n                facPath=\"$DEEPDIVE_GROUNDING_DIR\"/factor/${factor}\n                mkdir -p \"$facPath\"\n                cd \"$facPath\"\n                echo $begin                      >weights_id_begin\n                echo $excludeEnd                 >weights_id_exclude_end\n                echo $(( $excludeEnd - $begin )) >weights_count\n                weightsCountTotal=$excludeEnd\n            done\n            echo $weightsCountTotal >\"$DEEPDIVE_GROUNDING_DIR\"/factor/weights_count\n        }\n        \n\n\n"
}
{
  "path": "process/grounding/global_weight_table/run.sh",
  "mode": "+x",
  "content": "#!/usr/bin/env bash\n# cmd_extractor  process/grounding/global_weight_table\n# {\"dependencies_\":[\"process/grounding/factor/inf_istrue_review_sentiment/materialize\"],\"style\":\"cmd_extractor\",\"cmd\":\"\\n        : ${DEEPDIVE_GROUNDING_DIR:=\\\"$DEEPDIVE_APP\\\"/run/model/grounding}\\n\\n        # set up a union view for all weight tables (\\\"dd_graph_weights\\\")\\n        deepdive create view 'dd_graph_weights' as '(SELECT \\\"id\\\"\\n     , \\\"isfixed\\\"\\n     , \\\"initvalue\\\"\\n     , '\\\\''inf_istrue_review_sentiment-'\\\\'' ||'\\\\''-'\\\\''|| CASE WHEN \\\"dd_weight_column_0\\\" IS NULL THEN '\\\\'''\\\\''\\n              ELSE \\\"dd_weight_column_0\\\" || '\\\\'''\\\\''  -- XXX CAST(... AS TEXT) unsupported by MySQL\\n          END AS \\\"description\\\"\\n     , NULL AS \\\"categories\\\"\\nFROM \\\"dd_weights_inf_istrue_review_sentiment\\\")'\\n        \",\"name\":\"process/grounding/global_weight_table\"}\nset -xeuo pipefail\ncd \"$(dirname \"$0\")\"\n\n\n\nexport DEEPDIVE_CURRENT_PROCESS_NAME='process/grounding/global_weight_table'\n\n        : ${DEEPDIVE_GROUNDING_DIR:=\"$DEEPDIVE_APP\"/run/model/grounding}\n\n        # set up a union view for all weight tables (\"dd_graph_weights\")\n        deepdive create view 'dd_graph_weights' as '(SELECT \"id\"\n     , \"isfixed\"\n     , \"initvalue\"\n     , '\\''inf_istrue_review_sentiment-'\\'' ||'\\''-'\\''|| CASE WHEN \"dd_weight_column_0\" IS NULL THEN '\\'''\\''\n              ELSE \"dd_weight_column_0\" || '\\'''\\''  -- XXX CAST(... AS TEXT) unsupported by MySQL\n          END AS \"description\"\n     , NULL AS \"categories\"\nFROM \"dd_weights_inf_istrue_review_sentiment\")'\n        \n\n\n"
}
{
  "path": "process/grounding/factor/inf_istrue_review_sentiment/assign_weight_id/run.sh",
  "mode": "+x",
  "content": "#!/usr/bin/env bash\n# cmd_extractor  process/grounding/factor/inf_istrue_review_sentiment/assign_weight_id\n# {\"dependencies_\":[\"process/grounding/weight_id_partition\"],\"style\":\"cmd_extractor\",\"cmd\":\"\\n            : ${DEEPDIVE_GROUNDING_DIR:=\\\"$DEEPDIVE_APP\\\"/run/model/grounding}\\n\\n            cd \\\"$DEEPDIVE_GROUNDING_DIR\\\"/factor/'inf_istrue_review_sentiment'\\n            baseId=$(cat weights_id_begin)\\n            inc=1\\n            \\n\\n            # assign weight ids according to the partition\\n            deepdive db assign_sequential_id 'dd_weights_inf_istrue_review_sentiment' id $baseId $inc\\n\\n            \\n        \",\"name\":\"process/grounding/factor/inf_istrue_review_sentiment/assign_weight_id\"}\nset -xeuo pipefail\ncd \"$(dirname \"$0\")\"\n\n\n\nexport DEEPDIVE_CURRENT_PROCESS_NAME='process/grounding/factor/inf_istrue_review_sentiment/assign_weight_id'\n\n            : ${DEEPDIVE_GROUNDING_DIR:=\"$DEEPDIVE_APP\"/run/model/grounding}\n\n            cd \"$DEEPDIVE_GROUNDING_DIR\"/factor/'inf_istrue_review_sentiment'\n            baseId=$(cat weights_id_begin)\n            inc=1\n            \n\n            # assign weight ids according to the partition\n            deepdive db assign_sequential_id 'dd_weights_inf_istrue_review_sentiment' id $baseId $inc\n\n            \n        \n\n\n"
}
{
  "path": "process/grounding/factor/inf_istrue_review_sentiment/dump/run.sh",
  "mode": "+x",
  "content": "#!/usr/bin/env bash\n# cmd_extractor  process/grounding/factor/inf_istrue_review_sentiment/dump\n# {\"dependencies_\":[\"process/grounding/factor/inf_istrue_review_sentiment/assign_weight_id\"],\"style\":\"cmd_extractor\",\"cmd\":\"\\n            : ${DEEPDIVE_GROUNDING_DIR:=\\\"$DEEPDIVE_APP\\\"/run/model/grounding}\\n            facPath=\\\"$DEEPDIVE_GROUNDING_DIR\\\"/factor/'inf_istrue_review_sentiment'\\n            mkdir -p \\\"$facPath\\\"\\n            cd \\\"$facPath\\\"\\n            find . \\\\( -name  'factors.part-*.bin.bz2' \\\\\\n                    -o -name 'nfactors.part-*'         \\\\\\n                    -o -name   'nedges.part-*'         \\\\\\n                   \\\\) -exec rm -rf {} +\\n            export DEEPDIVE_LOAD_FORMAT=tsv\\n            export DEEPDIVE_UNLOAD_MATERIALIZED=false\\n\\n            # dump the factors joining the assigned weight ids, converting into binary format for the inference engine\\n            deepdive compute execute \\\\\\n                input_sql='SELECT \\\"weights\\\".\\\"id\\\" AS \\\"weight_id\\\"\\n     , \\\"factors\\\".\\\"review_sentiment.R0.id\\\"\\nFROM \\\"dd_factors_inf_istrue_review_sentiment\\\" \\\"factors\\\", \\\"dd_weights_inf_istrue_review_sentiment\\\" \\\"weights\\\"\\n\\nWHERE \\\"factors\\\".\\\"dd_weight_column_0\\\" = \\\"weights\\\".\\\"dd_weight_column_0\\\"' \\\\\\n                command='\\n                    # also record the factor count\\n                    tee >(wc -l >nfactors.part-${DEEPDIVE_CURRENT_PROCESS_INDEX}) |\\n                    format_converter factor /dev/stdin >(pbzip2 >factors.part-${DEEPDIVE_CURRENT_PROCESS_INDEX}.bin.bz2) 0 1 original 1 |\\n                    # and the edge count\\n                    tee nedges.part-${DEEPDIVE_CURRENT_PROCESS_INDEX}\\n                ' \\\\\\n                output_relation=\\n        \",\"name\":\"process/grounding/factor/inf_istrue_review_sentiment/dump\"}\nset -xeuo pipefail\ncd \"$(dirname \"$0\")\"\n\n\n\nexport DEEPDIVE_CURRENT_PROCESS_NAME='process/grounding/factor/inf_istrue_review_sentiment/dump'\n\n            : ${DEEPDIVE_GROUNDING_DIR:=\"$DEEPDIVE_APP\"/run/model/grounding}\n            facPath=\"$DEEPDIVE_GROUNDING_DIR\"/factor/'inf_istrue_review_sentiment'\n            mkdir -p \"$facPath\"\n            cd \"$facPath\"\n            find . \\( -name  'factors.part-*.bin.bz2' \\\n                    -o -name 'nfactors.part-*'         \\\n                    -o -name   'nedges.part-*'         \\\n                   \\) -exec rm -rf {} +\n            export DEEPDIVE_LOAD_FORMAT=tsv\n            export DEEPDIVE_UNLOAD_MATERIALIZED=false\n\n            # dump the factors joining the assigned weight ids, converting into binary format for the inference engine\n            deepdive compute execute \\\n                input_sql='SELECT \"weights\".\"id\" AS \"weight_id\"\n     , \"factors\".\"review_sentiment.R0.id\"\nFROM \"dd_factors_inf_istrue_review_sentiment\" \"factors\", \"dd_weights_inf_istrue_review_sentiment\" \"weights\"\n\nWHERE \"factors\".\"dd_weight_column_0\" = \"weights\".\"dd_weight_column_0\"' \\\n                command='\n                    # also record the factor count\n                    tee >(wc -l >nfactors.part-${DEEPDIVE_CURRENT_PROCESS_INDEX}) |\n                    format_converter factor /dev/stdin >(pbzip2 >factors.part-${DEEPDIVE_CURRENT_PROCESS_INDEX}.bin.bz2) 0 1 original 1 |\n                    # and the edge count\n                    tee nedges.part-${DEEPDIVE_CURRENT_PROCESS_INDEX}\n                ' \\\n                output_relation=\n        \n\n\n"
}
{
  "path": "process/grounding/factor/inf_istrue_review_sentiment/dump_weights/run.sh",
  "mode": "+x",
  "content": "#!/usr/bin/env bash\n# cmd_extractor  process/grounding/factor/inf_istrue_review_sentiment/dump_weights\n# {\"dependencies_\":[\"process/grounding/factor/inf_istrue_review_sentiment/assign_weight_id\"],\"style\":\"cmd_extractor\",\"cmd\":\"\\n            : ${DEEPDIVE_GROUNDING_DIR:=\\\"$DEEPDIVE_APP\\\"/run/model/grounding}\\n            facPath=\\\"$DEEPDIVE_GROUNDING_DIR\\\"/factor/'inf_istrue_review_sentiment'\\n            mkdir -p \\\"$facPath\\\"\\n            cd \\\"$facPath\\\"\\n            find . \\\\( -name  'weights.part-*.bin.bz2' \\\\\\n                   \\\\) -exec rm -rf {} +\\n            export DEEPDIVE_LOAD_FORMAT=tsv\\n            export DEEPDIVE_UNLOAD_MATERIALIZED=false\\n\\n            # flag that signals whether to reuse weights or not\\n            reuseFlag=\\\"$DEEPDIVE_GROUNDING_DIR\\\"/factor/weights.reuse\\n\\n            # dump the weights (except the description column), converting into binary format for the inference engine\\n            deepdive compute execute \\\\\\n                input_sql=\\\"$(if [[ -e \\\"$reuseFlag\\\" ]]; then\\n                    echo 'SELECT \\\"w\\\".\\\"id\\\"\\n     , CASE WHEN w.isfixed THEN 1 ELSE 0 END\\n     , COALESCE(reuse.weight, w.initvalue, 0)\\nFROM \\\"dd_weights_inf_istrue_review_sentiment\\\" \\\"w\\\"\\nLEFT OUTER JOIN \\\"dd_graph_weights_reuse\\\" \\\"reuse\\\" ON \\\"reuse\\\".\\\"description\\\" = '\\\\''inf_istrue_review_sentiment-'\\\\'' ||'\\\\''-'\\\\''|| CASE WHEN \\\"dd_weight_column_0\\\" IS NULL THEN '\\\\'''\\\\''\\n              ELSE \\\"dd_weight_column_0\\\" || '\\\\'''\\\\''  -- XXX CAST(... AS TEXT) unsupported by MySQL\\n          END'\\n                else\\n                    echo 'SELECT \\\"id\\\"\\n     , CASE WHEN isfixed THEN 1 ELSE 0 END\\n     , COALESCE(initvalue, 0)\\nFROM \\\"dd_weights_inf_istrue_review_sentiment\\\"'\\n                fi)\\\" \\\\\\n                command='\\n                    format_converter weight /dev/stdin >(pbzip2 >weights.part-${DEEPDIVE_CURRENT_PROCESS_INDEX}.bin.bz2)\\n                ' \\\\\\n                output_relation=\\n        \",\"name\":\"process/grounding/factor/inf_istrue_review_sentiment/dump_weights\"}\nset -xeuo pipefail\ncd \"$(dirname \"$0\")\"\n\n\n\nexport DEEPDIVE_CURRENT_PROCESS_NAME='process/grounding/factor/inf_istrue_review_sentiment/dump_weights'\n\n            : ${DEEPDIVE_GROUNDING_DIR:=\"$DEEPDIVE_APP\"/run/model/grounding}\n            facPath=\"$DEEPDIVE_GROUNDING_DIR\"/factor/'inf_istrue_review_sentiment'\n            mkdir -p \"$facPath\"\n            cd \"$facPath\"\n            find . \\( -name  'weights.part-*.bin.bz2' \\\n                   \\) -exec rm -rf {} +\n            export DEEPDIVE_LOAD_FORMAT=tsv\n            export DEEPDIVE_UNLOAD_MATERIALIZED=false\n\n            # flag that signals whether to reuse weights or not\n            reuseFlag=\"$DEEPDIVE_GROUNDING_DIR\"/factor/weights.reuse\n\n            # dump the weights (except the description column), converting into binary format for the inference engine\n            deepdive compute execute \\\n                input_sql=\"$(if [[ -e \"$reuseFlag\" ]]; then\n                    echo 'SELECT \"w\".\"id\"\n     , CASE WHEN w.isfixed THEN 1 ELSE 0 END\n     , COALESCE(reuse.weight, w.initvalue, 0)\nFROM \"dd_weights_inf_istrue_review_sentiment\" \"w\"\nLEFT OUTER JOIN \"dd_graph_weights_reuse\" \"reuse\" ON \"reuse\".\"description\" = '\\''inf_istrue_review_sentiment-'\\'' ||'\\''-'\\''|| CASE WHEN \"dd_weight_column_0\" IS NULL THEN '\\'''\\''\n              ELSE \"dd_weight_column_0\" || '\\'''\\''  -- XXX CAST(... AS TEXT) unsupported by MySQL\n          END'\n                else\n                    echo 'SELECT \"id\"\n     , CASE WHEN isfixed THEN 1 ELSE 0 END\n     , COALESCE(initvalue, 0)\nFROM \"dd_weights_inf_istrue_review_sentiment\"'\n                fi)\" \\\n                command='\n                    format_converter weight /dev/stdin >(pbzip2 >weights.part-${DEEPDIVE_CURRENT_PROCESS_INDEX}.bin.bz2)\n                ' \\\n                output_relation=\n        \n\n\n"
}
{
  "path": "process/grounding/combine_factorgraph/run.sh",
  "mode": "+x",
  "content": "#!/usr/bin/env bash\n# cmd_extractor  process/grounding/combine_factorgraph\n# {\"dependencies_\":[\"process/grounding/variable/review_sentiment/dump\",\"process/grounding/factor/inf_istrue_review_sentiment/dump\",\"process/grounding/factor/inf_istrue_review_sentiment/dump_weights\",\"process/grounding/global_weight_table\"],\"output_\":\"model/factorgraph\",\"style\":\"cmd_extractor\",\"cmd\":\"\\n        : ${DEEPDIVE_GROUNDING_DIR:=\\\"$DEEPDIVE_APP\\\"/run/model/grounding}\\n        : ${DEEPDIVE_FACTORGRAPH_DIR:=\\\"$DEEPDIVE_APP\\\"/run/model/factorgraph}\\n\\n        # create a fresh empty directory for the new combined factor graph\\n        rm -rf   \\\"$DEEPDIVE_FACTORGRAPH_DIR\\\"\\n        mkdir -p \\\"$DEEPDIVE_FACTORGRAPH_DIR\\\"\\n        cd \\\"$DEEPDIVE_FACTORGRAPH_DIR\\\"\\n\\n        # create symlinks to the grounded binaries by enumerating variables and factors\\n        for v in 'review_sentiment'; do\\n            mkdir -p variables/\\\"$v\\\"\\n            find \\\"$DEEPDIVE_GROUNDING_DIR\\\"/variable/\\\"$v\\\" \\\\\\n                -name 'variables.part-*.bin.bz2' -exec ln -sfnv -t variables/\\\"$v\\\"/ {} + \\\\\\n                #\\n        done\\n        for f in 'inf_istrue_review_sentiment'; do\\n            mkdir -p {factors,weights}/\\\"$f\\\"\\n            find \\\"$DEEPDIVE_GROUNDING_DIR\\\"/factor/\\\"$f\\\" \\\\\\n                -name 'factors.part-*.bin.bz2' -exec ln -sfnv -t factors/\\\"$f\\\"/ {} + \\\\\\n                -o \\\\\\n                -name 'weights.part-*.bin.bz2' -exec ln -sfnv -t weights/\\\"$f\\\"/ {} + \\\\\\n                #\\n        done\\n\\n        # generate the metadata for the inference engine\\n        {\\n            # first line with counts of variables and edges in the grounded factor graph\\n            cd \\\"$DEEPDIVE_GROUNDING_DIR\\\"\\n            sumup() { { tr '\\\\n' +; echo 0; } | bc; }\\n            counts=()\\n            counts+=($(cat factor/weights_count))\\n            # sum up the number of factors and edges\\n            counts+=($(cat variable_count))\\n            cd factor\\n            counts+=($(find 'inf_istrue_review_sentiment' -name 'nfactors.part-*' -exec cat {} + | sumup))\\n            counts+=($(find 'inf_istrue_review_sentiment' -name 'nedges.part-*'   -exec cat {} + | sumup))\\n            (IFS=,; echo \\\"${counts[*]}\\\")\\n            # second line with file paths\\n            paths=(\\\"$DEEPDIVE_FACTORGRAPH_DIR\\\"/{weights,variables,factors,edges})\\n            (IFS=,; echo \\\"${paths[*]}\\\")\\n        } >meta\\n        \",\"name\":\"process/grounding/combine_factorgraph\"}\nset -xeuo pipefail\ncd \"$(dirname \"$0\")\"\n\n\n\nexport DEEPDIVE_CURRENT_PROCESS_NAME='process/grounding/combine_factorgraph'\n\n        : ${DEEPDIVE_GROUNDING_DIR:=\"$DEEPDIVE_APP\"/run/model/grounding}\n        : ${DEEPDIVE_FACTORGRAPH_DIR:=\"$DEEPDIVE_APP\"/run/model/factorgraph}\n\n        # create a fresh empty directory for the new combined factor graph\n        rm -rf   \"$DEEPDIVE_FACTORGRAPH_DIR\"\n        mkdir -p \"$DEEPDIVE_FACTORGRAPH_DIR\"\n        cd \"$DEEPDIVE_FACTORGRAPH_DIR\"\n\n        # create symlinks to the grounded binaries by enumerating variables and factors\n        for v in 'review_sentiment'; do\n            mkdir -p variables/\"$v\"\n            find \"$DEEPDIVE_GROUNDING_DIR\"/variable/\"$v\" \\\n                -name 'variables.part-*.bin.bz2' -exec ln -sfnv -t variables/\"$v\"/ {} + \\\n                #\n        done\n        for f in 'inf_istrue_review_sentiment'; do\n            mkdir -p {factors,weights}/\"$f\"\n            find \"$DEEPDIVE_GROUNDING_DIR\"/factor/\"$f\" \\\n                -name 'factors.part-*.bin.bz2' -exec ln -sfnv -t factors/\"$f\"/ {} + \\\n                -o \\\n                -name 'weights.part-*.bin.bz2' -exec ln -sfnv -t weights/\"$f\"/ {} + \\\n                #\n        done\n\n        # generate the metadata for the inference engine\n        {\n            # first line with counts of variables and edges in the grounded factor graph\n            cd \"$DEEPDIVE_GROUNDING_DIR\"\n            sumup() { { tr '\\n' +; echo 0; } | bc; }\n            counts=()\n            counts+=($(cat factor/weights_count))\n            # sum up the number of factors and edges\n            counts+=($(cat variable_count))\n            cd factor\n            counts+=($(find 'inf_istrue_review_sentiment' -name 'nfactors.part-*' -exec cat {} + | sumup))\n            counts+=($(find 'inf_istrue_review_sentiment' -name 'nedges.part-*'   -exec cat {} + | sumup))\n            (IFS=,; echo \"${counts[*]}\")\n            # second line with file paths\n            paths=(\"$DEEPDIVE_FACTORGRAPH_DIR\"/{weights,variables,factors,edges})\n            (IFS=,; echo \"${paths[*]}\")\n        } >meta\n        \n\n\n"
}
{
  "path": "process/model/learning/run.sh",
  "mode": "+x",
  "content": "#!/usr/bin/env bash\n# cmd_extractor  process/model/learning\n# {\"dependencies_\":[\"model/factorgraph\"],\"output_\":\"model/weights\",\"style\":\"cmd_extractor\",\"cmd\":\"mkdir -p ../../../model && cd ../../../model\\n            mkdir -p weights\\n            [ -d factorgraph ] || error \\\"No factorgraph found\\\"\\n            # run inference engine for learning and inference\\n            flatten() { find -L \\\"$@\\\" -type f -exec pbzip2 -c -d -k {} +; }\\n            sampler-dw \\\\\\n                gibbs \\\\\\n                -w <(flatten factorgraph/weights) \\\\\\n                -v <(flatten factorgraph/variables) \\\\\\n                -f <(flatten factorgraph/factors) \\\\\\n                -m factorgraph/meta \\\\\\n                -o weights \\\\\\n                -l 1000 -s 1 -i 1000 --alpha 0.01 --sample_evidence\\n            mkdir -p probabilities\\n            mv -f weights/inference_result.out.text probabilities/\\n        \",\"name\":\"process/model/learning\"}\nset -xeuo pipefail\ncd \"$(dirname \"$0\")\"\n\n\n\nexport DEEPDIVE_CURRENT_PROCESS_NAME='process/model/learning'\nmkdir -p ../../../model && cd ../../../model\n            mkdir -p weights\n            [ -d factorgraph ] || error \"No factorgraph found\"\n            # run inference engine for learning and inference\n            flatten() { find -L \"$@\" -type f -exec pbzip2 -c -d -k {} +; }\n            sampler-dw \\\n                gibbs \\\n                -w <(flatten factorgraph/weights) \\\n                -v <(flatten factorgraph/variables) \\\n                -f <(flatten factorgraph/factors) \\\n                -m factorgraph/meta \\\n                -o weights \\\n                -l 1000 -s 1 -i 1000 --alpha 0.01 --sample_evidence\n            mkdir -p probabilities\n            mv -f weights/inference_result.out.text probabilities/\n        \n\n\n"
}
{
  "path": "process/model/inference/run.sh",
  "mode": "+x",
  "content": "#!/usr/bin/env bash\n# cmd_extractor  process/model/inference\n# {\"dependencies_\":[\"model/factorgraph\",\"model/weights\"],\"output_\":\"model/probabilities\",\"style\":\"cmd_extractor\",\"cmd\":\"mkdir -p ../../../model && cd ../../../model\\n            [ -d factorgraph ] || error \\\"No factorgraph found\\\"\\n            if [[ factorgraph/weights -nt probabilities/inference_result.out.text ]]; then\\n                # no need to run inference unless the weights are fresher\\n                # XXX this skipping may cause confusion\\n                # run sampler for performing inference with given weights without learning\\n                flatten() { find -L \\\"$@\\\" -type f -exec pbzip2 -c -d -k {} +; }\\n                sampler-dw \\\\\\n                    gibbs \\\\\\n                    -w <(flatten factorgraph/weights) \\\\\\n                    -v <(flatten factorgraph/variables) \\\\\\n                    -f <(flatten factorgraph/factors) \\\\\\n                    -m factorgraph/meta \\\\\\n                    -o weights \\\\\\n                    -l 1000 -s 1 -i 1000 --alpha 0.01 --sample_evidence \\\\\\n                    -l 0 \\\\\\n                    #\\n                mkdir -p probabilities\\n                mv -f weights/inference_result.out.text probabilities/\\n            fi\\n        \",\"name\":\"process/model/inference\"}\nset -xeuo pipefail\ncd \"$(dirname \"$0\")\"\n\n\n\nexport DEEPDIVE_CURRENT_PROCESS_NAME='process/model/inference'\nmkdir -p ../../../model && cd ../../../model\n            [ -d factorgraph ] || error \"No factorgraph found\"\n            if [[ factorgraph/weights -nt probabilities/inference_result.out.text ]]; then\n                # no need to run inference unless the weights are fresher\n                # XXX this skipping may cause confusion\n                # run sampler for performing inference with given weights without learning\n                flatten() { find -L \"$@\" -type f -exec pbzip2 -c -d -k {} +; }\n                sampler-dw \\\n                    gibbs \\\n                    -w <(flatten factorgraph/weights) \\\n                    -v <(flatten factorgraph/variables) \\\n                    -f <(flatten factorgraph/factors) \\\n                    -m factorgraph/meta \\\n                    -o weights \\\n                    -l 1000 -s 1 -i 1000 --alpha 0.01 --sample_evidence \\\n                    -l 0 \\\n                    #\n                mkdir -p probabilities\n                mv -f weights/inference_result.out.text probabilities/\n            fi\n        \n\n\n"
}
{
  "path": "process/model/load_weights/run.sh",
  "mode": "+x",
  "content": "#!/usr/bin/env bash\n# cmd_extractor  process/model/load_weights\n# {\"dependencies_\":[\"model/weights\"],\"output_\":\"data/model/weights\",\"style\":\"cmd_extractor\",\"cmd\":\"mkdir -p ../../../model && cd ../../../model\\n            # load weights to database\\n            deepdive create table dd_inference_result_weights \\\\\\n                id:BIGINT:'PRIMARY KEY' \\\\\\n                weight:'DOUBLE PRECISION' \\\\\\n                #\\n            cat weights/inference_result.out.weights.text |\\n            tr ' ' '\\\\t' | DEEPDIVE_LOAD_FORMAT=tsv \\\\\\n            deepdive load dd_inference_result_weights /dev/stdin\\n\\n            # create views\\n            deepdive create view dd_inference_result_weights_mapping as '\\n                SELECT dd_graph_weights.*, dd_inference_result_weights.weight FROM\\n                dd_graph_weights JOIN dd_inference_result_weights ON dd_graph_weights.id = dd_inference_result_weights.id\\n                ORDER BY abs(weight) DESC\\n            '\\n\\n            deepdive create view dd_inference_result_variables_mapped_weights as '\\n                SELECT * FROM dd_inference_result_weights_mapping\\n                ORDER BY abs(weight) DESC\\n            '\\n        \",\"name\":\"process/model/load_weights\"}\nset -xeuo pipefail\ncd \"$(dirname \"$0\")\"\n\n\n\nexport DEEPDIVE_CURRENT_PROCESS_NAME='process/model/load_weights'\nmkdir -p ../../../model && cd ../../../model\n            # load weights to database\n            deepdive create table dd_inference_result_weights \\\n                id:BIGINT:'PRIMARY KEY' \\\n                weight:'DOUBLE PRECISION' \\\n                #\n            cat weights/inference_result.out.weights.text |\n            tr ' ' '\\t' | DEEPDIVE_LOAD_FORMAT=tsv \\\n            deepdive load dd_inference_result_weights /dev/stdin\n\n            # create views\n            deepdive create view dd_inference_result_weights_mapping as '\n                SELECT dd_graph_weights.*, dd_inference_result_weights.weight FROM\n                dd_graph_weights JOIN dd_inference_result_weights ON dd_graph_weights.id = dd_inference_result_weights.id\n                ORDER BY abs(weight) DESC\n            '\n\n            deepdive create view dd_inference_result_variables_mapped_weights as '\n                SELECT * FROM dd_inference_result_weights_mapping\n                ORDER BY abs(weight) DESC\n            '\n        \n\n\n"
}
{
  "path": "process/model/load_probabilities/run.sh",
  "mode": "+x",
  "content": "#!/usr/bin/env bash\n# cmd_extractor  process/model/load_probabilities\n# {\"dependencies_\":[\"model/probabilities\"],\"output_\":\"data/model/probabilities\",\"style\":\"cmd_extractor\",\"cmd\":\"mkdir -p ../../../model && cd ../../../model\\n            # load weights to database\\n            deepdive create table dd_inference_result_variables \\\\\\n                id:BIGINT \\\\\\n                category:BIGINT \\\\\\n                expectation:'DOUBLE PRECISION' \\\\\\n                #\\n            cat probabilities/inference_result.out.text |\\n            tr ' ' '\\\\t' | DEEPDIVE_LOAD_FORMAT=tsv \\\\\\n            deepdive load dd_inference_result_variables /dev/stdin\\n\\n            # create a view for each app schema variable\\n            \\n            deepdive create view 'review_sentiment_label_inference' as '\\n                SELECT review_sentiment.*, mir.category, mir.expectation FROM\\n                review_sentiment, dd_inference_result_variables mir\\n                WHERE review_sentiment.id = mir.id\\n                ORDER BY mir.expectation DESC\\n                '\\n        \",\"name\":\"process/model/load_probabilities\"}\nset -xeuo pipefail\ncd \"$(dirname \"$0\")\"\n\n\n\nexport DEEPDIVE_CURRENT_PROCESS_NAME='process/model/load_probabilities'\nmkdir -p ../../../model && cd ../../../model\n            # load weights to database\n            deepdive create table dd_inference_result_variables \\\n                id:BIGINT \\\n                category:BIGINT \\\n                expectation:'DOUBLE PRECISION' \\\n                #\n            cat probabilities/inference_result.out.text |\n            tr ' ' '\\t' | DEEPDIVE_LOAD_FORMAT=tsv \\\n            deepdive load dd_inference_result_variables /dev/stdin\n\n            # create a view for each app schema variable\n            \n            deepdive create view 'review_sentiment_label_inference' as '\n                SELECT review_sentiment.*, mir.category, mir.expectation FROM\n                review_sentiment, dd_inference_result_variables mir\n                WHERE review_sentiment.id = mir.id\n                ORDER BY mir.expectation DESC\n                '\n        \n\n\n"
}
{
  "path": "process/model/calibration/run.sh",
  "mode": "+x",
  "content": "#!/usr/bin/env bash\n# cmd_extractor  process/model/calibration\n# {\"dependencies_\":[\"data/model/probabilities\",\"process/model/load_probabilities\"],\"output_\":\"model/calibration-plots\",\"style\":\"cmd_extractor\",\"cmd\":\"\\n            d=../../../model/calibration-plots && mkdir -p \\\"$d\\\" && cd \\\"$d\\\"\\n            # XXX a legacy location under the current run directory for backward compatibility\\n            extraOutput=\\\"${DEEPDIVE_OUTPUT:-../../RUNNING}\\\"/calibration && mkdir -p \\\"$extraOutput\\\"\\n            DEEPDIVE_CALIBRATION_NUM_BUCKETS=10\\n            \\n            # create a view and draw a calibration plot for variable null\\n            deepdive db create_calibration_view 'review_sentiment' 'label'\\n            draw_calibration_plot      'review_sentiment' 'label'\\n            # XXX keeping a duplicate copy under the current run directory for backward compatibility\\n            cp -a 'review_sentiment_label'.* \\\"$extraOutput\\\"/\\n            \\n        \",\"name\":\"process/model/calibration\"}\nset -xeuo pipefail\ncd \"$(dirname \"$0\")\"\n\n\n\nexport DEEPDIVE_CURRENT_PROCESS_NAME='process/model/calibration'\n\n            d=../../../model/calibration-plots && mkdir -p \"$d\" && cd \"$d\"\n            # XXX a legacy location under the current run directory for backward compatibility\n            extraOutput=\"${DEEPDIVE_OUTPUT:-../../RUNNING}\"/calibration && mkdir -p \"$extraOutput\"\n            DEEPDIVE_CALIBRATION_NUM_BUCKETS=10\n            \n            # create a view and draw a calibration plot for variable null\n            deepdive db create_calibration_view 'review_sentiment' 'label'\n            draw_calibration_plot      'review_sentiment' 'label'\n            # XXX keeping a duplicate copy under the current run directory for backward compatibility\n            cp -a 'review_sentiment_label'.* \"$extraOutput\"/\n            \n        \n\n\n"
}
